# -*- coding: utf-8 -*-
"""Copy of foods.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1buLjKOv1tZshexoX4WBHldNkWYOuzzMY
"""

import tensorflow as tf

import numpy as np
import matplotlib.pyplot as plt
import os
import tensorflow_hub as hub
import tensorflow_datasets as tfds
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import logging
logger = tf.get_logger()
logger.setLevel(logging.ERROR)

from google.colab import drive
drive.mount('/content/drive/')

base_dir = '/content/drive/My Drive/nn project'


train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'test')
BATCH_SIZE = 32
IMG_RES = (224, 224)

training_set = image_dataset_from_directory(train_dir,
                                             shuffle=True,
                                             batch_size=BATCH_SIZE,
                                             image_size=IMG_RES)
validation_set = image_dataset_from_directory(validation_dir,
                                                  shuffle=True,
                                                  batch_size=BATCH_SIZE,
                                                  image_size=IMG_RES)

num_training_examples = 241
num_classes = 3

train_image_generator = ImageDataGenerator(
      rescale = 1./255,
	  rotation_range=40,
      horizontal_flip=True,
      fill_mode='nearest')

validation_image_generator = ImageDataGenerator(
      rescale = 1./255,
	  rotation_range=40,
      horizontal_flip=True,
      fill_mode='nearest')

def format_image(image, label):
  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0
  return image, label
IMAGE_RES = 224
train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                           directory=train_dir,
                                                           target_size=(IMAGE_RES,IMAGE_RES), 
                                                           shuffle=True,
                                                           class_mode='sparse')
val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                              directory=validation_dir,
                                                              shuffle=False,
                                                              target_size=(IMAGE_RES,IMAGE_RES), 
                                                              class_mode='sparse')

URL = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
feature_extractor = hub.KerasLayer(URL,
                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))

feature_extractor.trainable = False

model = tf.keras.Sequential([
  feature_extractor,
  layers.Dense(num_classes)
])

model.summary()

model.compile(
  optimizer='adam',
  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

EPOCHS = 10

history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=int(np.ceil(train_data_gen.n / float(BATCH_SIZE))),
    epochs=EPOCHS,
    validation_data=val_data_gen,
    validation_steps=int(np.ceil(val_data_gen.n / float(BATCH_SIZE)))
)

